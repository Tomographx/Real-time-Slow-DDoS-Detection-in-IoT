{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8632a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7dcb7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r'F:\\dataset\\merged csv\\dataset_balance.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "dict_2classes = {'DDoS-SlowLoris': 'Attack', 'BenignTraffic': 'Benign'}\n",
    "df['label'] = df['label'].map(dict_2classes)\n",
    "df = df.dropna(subset=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "540f6e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = [\n",
    "    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "    'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
    "    'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "    'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
    "    'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "    'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "    'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min',\n",
    "    'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "    'Radius', 'Covariance', 'Variance', 'Weight'\n",
    "]\n",
    "X = df[X_columns]\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e4510a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2302248",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25215466",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],  \n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(n_jobs=-1, max_iter=1000),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "start_train_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "end_train_time = time.time()\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5100e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pred_time = time.time()\n",
    "y_pred = best_model.predict(X_test)\n",
    "end_pred_time = time.time()\n",
    "training_duration = end_train_time - start_train_time\n",
    "prediction_duration = end_pred_time - start_pred_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c29b9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating per-case prediction time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9371/9371 [00:00<00:00, 16717.47it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating per-case prediction time...\")\n",
    "per_case_times = []\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    x_single = X_test[i].reshape(1, -1)\n",
    "    start_case = time.time()\n",
    "    _ = best_model.predict(x_single)\n",
    "    end_case = time.time()\n",
    "    elapsed_ms = (end_case - start_case) * 1000\n",
    "    per_case_times.append(elapsed_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "076e0aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-case prediction time saved to per_case_prediction_time_LR_optimal.csv.\n"
     ]
    }
   ],
   "source": [
    "per_case_df = pd.DataFrame({'CaseIndex': range(len(per_case_times)), 'PredictionTime_ms': per_case_times})\n",
    "per_case_df.to_csv(\"per_case_prediction_time_LR_optimal.csv\", index=False)\n",
    "print(\"Per-case prediction time saved to per_case_prediction_time_LR_optimal.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97750178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Prediction Time per Case: 0.0586 ms\n"
     ]
    }
   ],
   "source": [
    "average_case_time_ms = np.mean(per_case_times)\n",
    "print(f\"Average Prediction Time per Case: {average_case_time_ms:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8deeb01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Optimized Logistic Regression (2-class) #####\n",
      "Accuracy: 0.8281933625013339\n",
      "Recall: 0.8281959568933279\n",
      "Precision: 0.8289715020723533\n",
      "F1 Score: 0.8280924895588302\n",
      "Training Time: 30.2006 seconds\n",
      "Prediction Time: 0.0010 seconds\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"##### Optimized Logistic Regression (2-class) #####\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(f\"Training Time: {training_duration:.4f} seconds\")\n",
    "print(f\"Prediction Time: {prediction_duration:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca25177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation results have been saved to result_LR_optimal.json.\n"
     ]
    }
   ],
   "source": [
    "result = {\n",
    "    \"Model\": \"LR_optimal\",\n",
    "    \"Accuracy\": round(float(acc), 6),\n",
    "    \"Recall\": round(float(recall), 6),\n",
    "    \"Precision\": round(float(precision), 6),\n",
    "    \"F1 Score\": round(float(f1), 6),\n",
    "    \"Training Time (s)\": round(float(training_duration), 4),\n",
    "    \"Prediction Time (s)\": round(float(prediction_duration), 4),\n",
    "    \"Avg Case Predict Time (ms)\": round(float(average_case_time_ms), 4)\n",
    "}\n",
    "\n",
    "with open(\"result_LR_optimal.json\", \"w\") as f:\n",
    "    json.dump(result, f, indent=4)\n",
    "\n",
    "print(\"Model evaluation results have been saved to result_LR_optimal.json.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a787fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee30e75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9371/9371 [00:00<00:00, 15320.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Avg Prediction Time per Case: 0.0623 ms\n",
      "ðŸ“Š Avg Flow Duration per Case: 34.37 ms\n",
      "\n",
      "##### Optimized Logistic Regression with Timing #####\n",
      "Accuracy: 0.8327819869811119\n",
      "Precision: 0.859713890170743\n",
      "Recall: 0.7953041622198506\n",
      "F1 Score: 0.826255682448165\n",
      "Training Time: 0.3314 seconds\n",
      "Prediction Time (total): 0.0010 seconds\n",
      "âœ… Result and timing comparison saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===== é…ç½® =====\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===== æ•°æ®åŠ è½½ =====\n",
    "csv_path = r'F:\\dataset\\merged csv\\dataset_balance.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# æ ‡ç­¾æ˜ å°„\n",
    "df['label'] = df['label'].map({\n",
    "    'DDoS-SlowLoris': 'Attack',\n",
    "    'BenignTraffic': 'Benign'\n",
    "})\n",
    "df = df.dropna(subset=['label'])\n",
    "df['label'] = df['label'].map({'Benign': 0, 'Attack': 1})\n",
    "\n",
    "# ç‰¹å¾åˆ—å®šä¹‰\n",
    "X_columns = [  # åŒ…å« flow_duration\n",
    "    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "    'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
    "    'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "    'ece_flag_number', 'cwr_flag_number', 'ack_count', 'syn_count',\n",
    "    'fin_count', 'urg_count', 'rst_count', 'HTTP', 'HTTPS', 'DNS',\n",
    "    'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP', 'UDP', 'DHCP', 'ARP',\n",
    "    'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min', 'Max', 'AVG', 'Std',\n",
    "    'Tot size', 'IAT', 'Number', 'Magnitue', 'Radius', 'Covariance',\n",
    "    'Variance', 'Weight'\n",
    "]\n",
    "\n",
    "X = df[X_columns].astype('float32')\n",
    "y = df['label'].astype('int32')\n",
    "\n",
    "# ç‰¹å¾æ ‡å‡†åŒ–\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ç‰¹å¾é€‰æ‹©ï¼ˆk=30ï¼‰\n",
    "k_best = 30\n",
    "selector = SelectKBest(score_func=f_classif, k=k_best)\n",
    "X_selected = selector.fit_transform(X_scaled, y)\n",
    "selected_features = np.array(X_columns)[selector.get_support()]\n",
    "\n",
    "# ä¿å­˜ flow_durationï¼ˆæœªç»ç¼©æ”¾çš„åŽŸå§‹å€¼ï¼‰\n",
    "flow_duration = df['flow_duration'].reset_index(drop=True)\n",
    "\n",
    "# è®­ç»ƒ/æµ‹è¯•é›†åˆ’åˆ†\n",
    "X_train, X_test, y_train, y_test, flow_train, flow_test = train_test_split(\n",
    "    X_selected, y, flow_duration,\n",
    "    test_size=0.2, random_state=SEED, stratify=y, shuffle=True\n",
    ")\n",
    "\n",
    "# æ¨¡åž‹è®­ç»ƒ\n",
    "model = LogisticRegression(\n",
    "    solver='liblinear',\n",
    "    penalty='l2',\n",
    "    class_weight='balanced',\n",
    "    max_iter=2000,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "start_train_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end_train_time = time.time()\n",
    "training_duration = end_train_time - start_train_time\n",
    "\n",
    "# æŽ¨ç†æ•´ä½“æ—¶é—´\n",
    "start_pred_time = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "end_pred_time = time.time()\n",
    "prediction_duration = end_pred_time - start_pred_time\n",
    "\n",
    "# ==== æ–°å¢žï¼šæ¯ä¸ª case çš„æŽ¨ç†æ—¶é—´ ====\n",
    "per_case_times = []\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    x_single = X_test[i].reshape(1, -1)\n",
    "    start_case = time.time()\n",
    "    _ = model.predict(x_single)\n",
    "    end_case = time.time()\n",
    "    elapsed_ms = (end_case - start_case) * 1000  # ms\n",
    "    per_case_times.append(elapsed_ms)\n",
    "\n",
    "# ä¿å­˜æ¯æ¡æ ·æœ¬çš„é¢„æµ‹æ—¶é—´ä¸Ž flow_duration å¯¹æ¯”\n",
    "comparison_df = pd.DataFrame({\n",
    "    'PredictionTime_ms': per_case_times,\n",
    "    'FlowDuration': flow_test.reset_index(drop=True)\n",
    "})\n",
    "comparison_df.to_csv('flow_vs_prediction_time.csv', index=False)\n",
    "\n",
    "# å¹³å‡å€¼å¯¹æ¯”è¾“å‡º\n",
    "avg_pred_time = np.mean(per_case_times)\n",
    "avg_flow_duration = np.mean(comparison_df['FlowDuration'])\n",
    "\n",
    "print(f\"\\nðŸ“Š Avg Prediction Time per Case: {avg_pred_time:.4f} ms\")\n",
    "print(f\"ðŸ“Š Avg Flow Duration per Case: {avg_flow_duration:.2f} ms\")\n",
    "\n",
    "# ==== æ€§èƒ½è¯„ä¼° ====\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# è¾“å‡ºè¯„ä¼°ç»“æžœ\n",
    "print(\"\\n##### Optimized Logistic Regression with Timing #####\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(f\"Training Time: {training_duration:.4f} seconds\")\n",
    "print(f\"Prediction Time (total): {prediction_duration:.4f} seconds\")\n",
    "\n",
    "# æœ€ç»ˆç»“æžœä¿å­˜\n",
    "result = {\n",
    "    \"Model\": \"LR_k30_L2_balanced\",\n",
    "    \"Selected Features\": selected_features.tolist(),\n",
    "    \"Accuracy\": float(acc),\n",
    "    \"Precision\": float(precision),\n",
    "    \"Recall\": float(recall),\n",
    "    \"F1\": float(f1),\n",
    "    \"Train Time (s)\": float(training_duration),\n",
    "    \"Predict Time (s)\": float(prediction_duration),\n",
    "    \"Avg Prediction Time per Case (ms)\": float(avg_pred_time),\n",
    "    \"Avg Flow Duration per Case (ms)\": float(avg_flow_duration)\n",
    "}\n",
    "\n",
    "with open(\"result_LR_k30_with_time.json\", \"w\") as f:\n",
    "    json.dump(result, f, indent=4)\n",
    "\n",
    "print(\"âœ… Result and timing comparison saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
